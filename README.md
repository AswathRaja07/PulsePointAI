# ğŸ¬ PulsePoint AI â€” Reel Generator

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JQXUgloZvpcNWOjkNV_DJDT2Noxms85S?usp=sharing)

**By:** Aswath Raja R  
**Tagline:** AI tool that converts long videos into short reels using emotional peaks.

---

## ï¿½ Overview

Mentors, educators, and creators produce hours of long-form content (lectures, workshops, podcasts).  
Modern viewers consume content in 30â€“60 second bursts.

**PulsePoint AI** solves this by automatically converting long videos into short reels using:

- Emotional peak detection
- Speech-to-text transcription
- Sentiment analysis
- Automatic video clipping

This makes education **snackable, shareable, and engagement-friendly**.

---

## âœ¨ Features

- Upload video OR paste YouTube link
- Whisper transcription (accurate speech-to-text)
- Emotional peak detection from transcript
- Sentiment scoring (Positive / Negative / Neutral)
- Automatic reel selection (top 3â€“5 clips)
- Fast video clipping via FFmpeg (no re-encode)
- Watch & download generated reels
- Clean Web UI (Streamlit)

---

## ğŸ§  How It Works

PulsePoint AI identifies "interesting" parts of video by combining:

1. **Speech-to-Text** â€” Whisper extracts transcript with timestamps
2. **Sentiment Analysis** â€” HuggingFace Transformers detect emotional intensity
3. **Peak Selection** â€” Top emotional segments chosen by confidence score
4. **Clip Extraction** â€” FFmpeg cuts reels instantly with stream copy

---

## ğŸ›  Tech Stack

### Backend / Processing
| Component | Tool |
|---|---|
| Speech-to-text | OpenAI Whisper |
| Sentiment analysis | HuggingFace Transformers |
| Video clipping | FFmpeg |
| Video download | yt-dlp |
| Model runtime | PyTorch |
| GPU Support | CUDA (Colab) |

### Frontend / UI
| Component | Tool |
|---|---|
| Web Framework | Streamlit |
| Reverse Tunnel | Ngrok |

---

## ğŸ“‚ Project Structure

```
PulsePointAI/
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ uploads/        # input video
â””â”€â”€ clips/          # generated reels
```

---

## ğŸš€ Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/PulsePointAI.git
   cd PulsePointAI
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ–¥ Usage

1. **Run the Streamlit App:**
   ```bash
   streamlit run app.py
   ```

2. **Use the UI:**
   - Upload a video **or**
   - Paste a YouTube link
   - Click **Generate Reels**
   - Preview or Download reels

---

## ğŸ“‹ Requirements

The `requirements.txt` file includes:

```
streamlit
yt-dlp
moviepy
openai-whisper
transformers
torch
ffmpeg-python
pyngrok
```

---

## ğŸ¥ Demo

Example placeholder:
```
https://drive.google.com/file/d/<YOUR_VIDEO_ID>/view
```

---

## ğŸ“¤ Output Format

You will get:
```
reel_1.mp4
reel_2.mp4
reel_3.mp4
...
```

Each reel contains a **high-impact emotional moment** extracted from the original video.

---

## ğŸ— Future Enhancements

- Vertical auto-cropping (MediaPipe)
- Dynamic captions (karaoke style)
- Topic-based clip grouping
- Hook headline generation
- Cloud deployment (Render / HF Spaces)

---

## ğŸ‘¤ Author

**Aswath Raja R**

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.